{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import joblib\n",
    "import quaternion as q\n",
    "import numpy as np\n",
    "from src.utils.render_utils import add_title, add_agent_view_on_w\n",
    "from src.models.autoencoder.autoenc import Embedder\n",
    "import copy\n",
    "from src.utils.camera_trajectory import go_forward, go_backward, rotate_n\n",
    "import imageio\n",
    "from IPython.display import HTML, display\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = joblib.load(\"sample_data/Elmira_random_traj.dat.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "embedder = Embedder(pretrained_ckpt='pretrained/autoenc_large.ckpt',\n",
    "                    img_res=128, w_size=128, coordinate_scale=32, w_ch=32, nerf_res=64, voxel_res=128)\n",
    "embedder = embedder.to(device).eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Embed RNR-Map along trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbdfc31b1e3d4bbd88e2367985b85ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ad01493624/codes/venv_rnr/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "w, w_mask = None, None\n",
    "\n",
    "T = len(data['rgb'])\n",
    "K = torch.eye(3)\n",
    "K[0,0] = (embedder.img_res/2.) / np.tan(np.deg2rad(90.0) / 2)\n",
    "K[1,1] = -(embedder.img_res/2.) / np.tan(np.deg2rad(90.0) / 2)\n",
    "K = K.unsqueeze(0).to(device)\n",
    "\n",
    "start_position = data['position'][0]\n",
    "start_rotation = q.from_float_array(data['rotation'][0])\n",
    "\n",
    "orig_Rt = np.eye(4)\n",
    "orig_Rt[:3,3] = start_position\n",
    "orig_Rt[:3,:3] = q.as_rotation_matrix(start_rotation)\n",
    "orig_Rt = np.linalg.inv(orig_Rt)\n",
    "\n",
    "view_size = data['rgb'][0].shape[0]\n",
    "time_embedding, time_rendering = [], []\n",
    "imgs = []\n",
    "for t in tqdm(range(T)):\n",
    "\n",
    "    Rt_t = np.eye(4)\n",
    "    Rt_t[:3,3] = data['position'][t]\n",
    "    Rt_t[:3,:3] = q.as_rotation_matrix(q.from_float_array(data['rotation'][t]))\n",
    "    Rt_t = np.linalg.inv(Rt_t)\n",
    "    Rt_t = Rt_t @ np.linalg.inv(orig_Rt)\n",
    "\n",
    "    rgb_t = torch.from_numpy(data['rgb'][t]/255.).unsqueeze(0).permute(0,3,1,2).to(device)\n",
    "    depth_t = torch.from_numpy(data['depth'][t]).unsqueeze(0).permute(0,3,1,2).to(device)\n",
    "\n",
    "    Rt_t = torch.from_numpy(Rt_t).unsqueeze(0).float().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        output = embedder.calculate_mask_func(depth_t*10.0, Rt_t, K)\n",
    "        sorted_indices, seq_unique_list, seq_unique_counts, _ = output\n",
    "        input_dict = {'rgb': rgb_t.unsqueeze(1),\n",
    "                      'depth': depth_t.unsqueeze(1),\n",
    "                    'sorted_indices': sorted_indices.unsqueeze(1),\n",
    "                    'seq_unique_counts': seq_unique_counts.unsqueeze(1),\n",
    "                      'seq_unique_list': seq_unique_list.unsqueeze(1)}\n",
    "        w, w_mask = embedder.embed_obs(input_dict, past_w=w, past_w_num_mask=w_mask)\n",
    "        recon_rgb, _ = embedder.generate(w, {'Rt': Rt_t.unsqueeze(1), 'K':K.unsqueeze(1)}, out_res=64)\n",
    "\n",
    "        orig_rgb = add_title(data['rgb'][t], 'Gt Image')\n",
    "        recon_rgb = (recon_rgb.squeeze().permute(1,2,0).detach().cpu() * 255).numpy().astype(np.uint8)\n",
    "        recon_rgb = cv2.resize(recon_rgb, (view_size, view_size))\n",
    "        recon_rgb = add_title(recon_rgb, 'Recon Image')\n",
    "\n",
    "        w_im = w.mean(0).mean(0).detach().cpu().numpy()\n",
    "        w_im = ((w_im - w_im.min())/(w_im.max()-w_im.min()) * 255).astype(np.uint8)\n",
    "        w_im = cv2.applyColorMap(w_im, cv2.COLORMAP_VIRIDIS)[:,:,::-1]\n",
    "        last_w_im = w_im.copy()\n",
    "\n",
    "        w_im = add_agent_view_on_w(w_im, Rt_t, embedder.coordinate_scale, embedder.w_size, agent_size=4, view_size=15)\n",
    "        w_im = cv2.resize(w_im, (view_size, view_size))\n",
    "        w_img = np.fliplr(w_im)\n",
    "        w_im = add_title(w_im, 'Map')\n",
    "\n",
    "        view_im = np.concatenate([orig_rgb, recon_rgb, w_im],1)\n",
    "\n",
    "        imgs.append(view_im)\n",
    "        cv2.imshow(\"view\", view_im[:,:,[2,1,0]])\n",
    "        key = cv2.waitKey(1)\n",
    "        if key == ord(\"q\"): break\n",
    "\n",
    "last_w = w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=demo/embedding_traj.gif>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageio.mimwrite('demo/embedding_traj.gif', imgs, fps=15)\n",
    "display(HTML('<img src={}>'.format(\"demo/embedding_traj.gif\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Explore inside RNR-Map\n",
    "- Press 'w, a, s, d' to move\n",
    "- Press 'q' to quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "Rt_current = torch.eye(4).unsqueeze(0).to(device).unsqueeze(1)\n",
    "while True:\n",
    "    with torch.no_grad():\n",
    "        rgb, _ = embedder.generate(last_w, {\"Rt\": Rt_current, 'K': K.unsqueeze(1)}, out_res=64)\n",
    "        rgb = (rgb.squeeze().permute(1,2,0).detach().cpu() * 255).numpy().astype(np.uint8)\n",
    "        rgb = cv2.resize(rgb, (data['rgb'][0].shape[0], data['rgb'][0].shape[0]))\n",
    "        rgb = add_title(rgb, 'Recon Image')\n",
    "        w_color = copy.deepcopy(last_w_im)\n",
    "        w_color = add_agent_view_on_w(w_color, Rt_current, embedder.coordinate_scale, embedder.w_size, agent_size=4, view_size=15)\n",
    "        w_color = np.fliplr(w_color)\n",
    "        w_color = add_title(w_color, 'Map')\n",
    "        view_im = np.concatenate([rgb, w_color],1)\n",
    "        cv2.imshow(\"view\", view_im[:,:,::-1])\n",
    "        key = cv2.waitKey(0)\n",
    "        if key == ord('q'): break\n",
    "        elif key == ord('a'):\n",
    "            Rt = rotate_n(n=-10.0).to(device)\n",
    "            Rt_current = (Rt@Rt_current.squeeze()).unsqueeze(0).unsqueeze(0)\n",
    "        elif key == ord('d'):\n",
    "            Rt = rotate_n(n=10.0).to(device)\n",
    "            Rt_current = (Rt@Rt_current.squeeze()).unsqueeze(0).unsqueeze(0)\n",
    "        elif key == ord(\"w\"):\n",
    "            Rt_current = go_forward(Rt_current, step=0.1)\n",
    "        elif key == ord('s'):\n",
    "            Rt_current = go_backward(Rt_current, step=0.1)\n",
    "        images.append(view_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=demo/explore_RNR_map.gif>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#imageio.mimwrite(\"demo/explore_RNR_map.gif\", images, fps=15)\n",
    "display(HTML('<img src={}>'.format(\"demo/explore_RNR_map.gif\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnr",
   "language": "python",
   "name": "rnr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
